{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:28.580796Z",
     "start_time": "2024-09-27T22:34:28.575461Z"
    }
   },
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "from unipressed import IdMappingClient, UniprotkbClient\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from Bio import Entrez"
   ],
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:30.682938Z",
     "start_time": "2024-09-27T22:34:28.622084Z"
    }
   },
   "cell_type": "code",
   "source": "gse = GEOparse.get_GEO(\"GSE12345\")",
   "id": "9dd5af074b6f3fad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Sep-2024 00:34:28 DEBUG utils - Directory ./ already exists. Skipping.\n",
      "28-Sep-2024 00:34:28 INFO GEOparse - File already exist: using local version.\n",
      "28-Sep-2024 00:34:28 INFO GEOparse - Parsing ./GSE12345_family.soft.gz: \n",
      "28-Sep-2024 00:34:28 DEBUG GEOparse - DATABASE: GeoMiame\n",
      "28-Sep-2024 00:34:28 DEBUG GEOparse - SERIES: GSE12345\n",
      "28-Sep-2024 00:34:28 DEBUG GEOparse - PLATFORM: GPL570\n",
      "/home/olivier/micromamba/envs/hskp_test/lib/python3.11/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "28-Sep-2024 00:34:29 DEBUG GEOparse - SAMPLE: GSM309986\n",
      "28-Sep-2024 00:34:29 DEBUG GEOparse - SAMPLE: GSM309987\n",
      "28-Sep-2024 00:34:29 DEBUG GEOparse - SAMPLE: GSM309988\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM309989\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM309990\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM309991\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310012\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310013\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310014\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310015\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310016\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310068\n",
      "28-Sep-2024 00:34:30 DEBUG GEOparse - SAMPLE: GSM310070\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:30.750107Z",
     "start_time": "2024-09-27T22:34:30.687258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate expression data from all samples into a single DataFrame\n",
    "gsm_dfs = []\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    gsm_df = gsm.table\n",
    "    gsm_df = gsm_df.set_index('ID_REF').rename(columns={'VALUE': gsm_name})\n",
    "    gsm_dfs.append(gsm_df)\n",
    "expression_df = pd.concat(gsm_dfs, axis=1)"
   ],
   "id": "664904de3678931a",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:30.860780Z",
     "start_time": "2024-09-27T22:34:30.840183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting platform data (there can be multiple ones)\n",
    "descriptive_columns_to_uniprot_source = {\n",
    "    'GB_ACC': 'EMBL-GenBank-DDBJ', \n",
    "    #'Gene Symbol': 'Gene_Name', \n",
    "    'ENTREZ_GENE_ID': 'GeneID', \n",
    "    'RefSeq Transcript ID': 'RefSeq_Nucleotide'\n",
    "}\n",
    "gpl_dfs = []\n",
    "for gpl in gse.gpls.values():\n",
    "    \n",
    "    if gpl.table.empty:\n",
    "        continue\n",
    "        \n",
    "    descr_column_found = False\n",
    "    for descr_column in descriptive_columns_to_uniprot_source.keys():\n",
    "        if descr_column in gpl.table.columns:\n",
    "            #cols_to_keep = ['ID', descr_column, 'Species Scientific Name']\n",
    "            cols_to_keep = ['ID', descr_column]\n",
    "            gpl_df = gpl.table[cols_to_keep]\n",
    "            gpl_dfs.append(gpl_df)\n",
    "            descr_column_found = True\n",
    "            break\n",
    "    \n",
    "    if not descr_column_found:\n",
    "        raise KeyError(f'Could not find a descriptive column in the GPL table. Found columns: {gpl.table.columns.to_list()}')\n",
    "            \n",
    "mapping_df = pd.concat(gpl_dfs, ignore_index=True).set_index('ID')"
   ],
   "id": "cb5ae100c62f6234",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:30.934963Z",
     "start_time": "2024-09-27T22:34:30.931448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# getting species name\n",
    "species_names = mapping_df['Species Scientific Name'].unique().tolist()\n",
    "if len(species_names) > 1:\n",
    "    raise ValueError('More than one species')\n",
    "\n",
    "species_name = species_names[0]\n",
    "mapping_df.drop(columns=['Species Scientific Name'], inplace=True)\n",
    "\"\"\""
   ],
   "id": "a82a96d17c798179",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:30.967187Z",
     "start_time": "2024-09-27T22:34:30.963867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_uniprot_ids(ids: list[str], source: str) -> dict:    \n",
    "    request = IdMappingClient.submit(source=source, dest=\"UniProtKB\", ids=ids)\n",
    "    while request.get_status() != 'FINISHED':\n",
    "        time.sleep(1)\n",
    "    return {result_dict['from'] : result_dict['to'] for result_dict in request.each_result()}"
   ],
   "id": "c980993f53bcd735",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:31.020181Z",
     "start_time": "2024-09-27T22:34:31.017595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_list(lst: list, chunksize: int):\n",
    "    return [lst[i: i + chunksize] for i in range(0, len(lst), chunksize)]"
   ],
   "id": "e016a4dc96b1368b",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mapping_df = mapping_df[:1000]",
   "id": "fc1caa77f29eddc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:34:33.457284Z",
     "start_time": "2024-09-27T22:34:31.117131Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "/tmp/ipykernel_4163/3745249323.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  mapping_df['uniprot_id'] = mapping_df[uniprot_columns].bfill(axis=1).iloc[:, 0]\n"
     ]
    }
   ],
   "execution_count": 130,
   "source": [
    "for i, col in enumerate(descriptive_columns_to_uniprot_source):\n",
    "    \n",
    "    if col in mapping_df.columns:\n",
    "        \n",
    "        # unique list of IDs for this type of ID\n",
    "        ids = mapping_df[col].dropna().unique().tolist()\n",
    "        \n",
    "        if ids:\n",
    "            source = descriptive_columns_to_uniprot_source[col]\n",
    "            chunks = chunk_list(ids, chunksize=2000)\n",
    "            mappings = {}\n",
    "            for chunk in tqdm(chunks):\n",
    "                # converting to uniprot IDs for all IDs comprised in this chunk\n",
    "                mapping = get_uniprot_ids(chunk, source)\n",
    "                mappings.update(mapping)\n",
    "                \n",
    "            # making a series out of this dict: index is previous ids while value is uniprot id\n",
    "            uniprot_mapping_series = pd.Series(mappings, name=f'uniprot_id_{i}')\n",
    "            # left join to get a new uniprot_id_{i} col where values are not NA where mapping[col].notna()\n",
    "            mapping_df = mapping_df.merge(uniprot_mapping_series, how='left', left_on=col, right_index=True)\n",
    "\n",
    "#getting list of uniprot id columns in dataframe\n",
    "uniprot_columns = [col for col in mapping_df.columns if col.startswith('uniprot_id_')]\n",
    "# coalescing all uniprot ids into a single uniprot_id column\n",
    "mapping_df['uniprot_id'] = mapping_df[uniprot_columns].bfill(axis=1).iloc[:, 0]\n",
    "mapping_df.drop(columns=uniprot_columns, inplace=True)\n",
    "    "
   ],
   "id": "eedf01dfb06af18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8de2f9923e8fc0c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
